# 面对AI的自信或不自信

我们首先要搞懂过度自信和不自信的定义。

我认为过度自信，在这样一个题目背景下，大概率指的是人们因为用大模型，所以对自己的能力或处境产生错误的估量，高估或低估。

高估是如何产生的？

第一，是最直接的现象性问题：除了在生产开发环境下，大部分我们所能接触到的大模型都是用户导向的。其普遍会产生一种迎合性偏误，如几乎所有ChatGPT用户都表示，当他们在询问AI他们的智力水平时，AI均给出了“远超常人”的评价，这显然极其严重地违背了基本的统计学原理。我们不难归纳，AI极容易生成直接阿谀奉承用户的内容——而事实也正如此，OpenAI一度因此问题回滚其模型版本，而Antropic的Claude模型更是直接以“以人为本”之由，一度将“用户观点”大于“实证观点”公开性地标榜为模型的底层逻辑，而被学界激烈批判。用户社群中，更是有诸多人将大模型作为“夸夸机”使用，甚至反复调试和撰写虚浮的设定或prompt，仅为得到一句轻飘飘的“鼓励”，长此以往，AI确实提高了我们的信心，但是也会产生错误和不符合现实的估计。

第二，则是更隐蔽的。即使在于我们自以为理性客观时，也常常不自觉地堕入AI底层所注定挖出的，更深的偏误。大模型的注意力机制与其统计性的本质，天生使得其会强化关注用户提出的关键词，并在此基础上微调回答的范式。在这种机制下，用户往往会从大模型口中听到对其观点的诠释与佐证，而不是全面客观的理性发散或反面批判。而在人类底层的认知机制中，我们又天生更喜爱选择性地采信那些符合我们既有认知的“关键点”，而乐意将不符合原认知或陌生的观点当作“异常值”并加以忽略。于是这便导致了一种主被动结合、双向强化的确认偏误。经由这种可得性启发和赫布理论联手的机制，用户在与AI的交互中，认知层面的最小自由能需求越来越低，用户固有而未辨真伪的朴素信念被不断看似合乎逻辑地强化。于是，大模型的回答，最终本质上是在预测用户的预测编码。于是用户便将在这种客制化的回音室，或通俗地说，信息茧房中，进入了一种盲目的“正反馈循环”，无法自拔。但是，科学性的认知过程需要可证伪性，在这样的正反馈循环中，最终我们以为得到的是自我满足和信心上的正反馈，却已经不自觉的落入了不可证伪的、自我信仰的认知负反馈——大模型最终会将我们以为可证伪的“自我信任”，潜移默化地转化为形而上学的“自我信仰”。

第三，是最重要，但常未被正确认识的“认知负债”问题。存在主义哲学家海德格尔提出了工具的两个状态，“顺手可用”和“现成之物”，在我正在撰写的这段文字本身，大模型是被分析的“现成之物”。但是在人们使用AI时，它的状态，是“顺手可用”的。“顺手可用”的工具，如同一件外套，我们不会常常关注和思考其是聚酯纤维或玉米淀粉做的，而只是感知穿上外套的后的暖意，将这股暖当作铰链式的惯习，并在这种温暖的认知中进行新的活动。“媒介即延伸”，在使用过程中，大模型正作为这样一种媒介，重塑了我们的认知，成为我们前额叶皮层的延伸——也就是，正如麦克卢汉所说的“所有工具都是感官的延伸”。在这种结构下，系统二的复杂思考，被外包给了大模型，而我们往往不自知地，只剩下系统一在做简单直觉和启发式的思维活动。我们分明将AI作为认知和思考的媒介与外包，却往往误以为那些详实和复杂的逻辑、精妙的洞见和论证，是自己的，于是，我们便产生了所谓的“认知负债”效应，或者再次通俗和切题地说——即“过度自信”。由MIT Media Lab 团队主导并上传至arXiv的最新预印本《Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task》直接证实了这一点。研究者们将多名被试分成两组，让他们在4个月中分别被允许和不允许使用AI撰写文本，并使用EEG监测其活动。结果显示，使用AI工具的学生，大脑连接明显较弱；而另一组则神经连接强烈，且分布广泛。在研究末尾，研究者将要求AI组和独立写作组一同在不使用AI的情况下，撰写同一主题的文章。研究发现，使用AI组的文章出现明显同质化，而另一组则反之。

那么，低估是如何产生的？我想这样的不自信，主要是源于大模型的强大使得个体产生了取代焦虑和意义危机。

第一，在取代焦虑上，诚然，大模型所具有的知识，我们读到太阳系毁灭都必然无法穷尽。但是，学者们早已告诫了我们无数次，将被取代的恰恰是畏惧AI、止步不前的人；而取代人的，则也不是AI，而是会用AI的人。从CNN到Transformer到Mamba，从LLM到MCP到AGI，AI正无时不刻不在发展，真正能解决问题的，从来只有跟上时代的浪潮，踏浪而行。而不是坐在岸上，从未改变，却日思夜想，怨天尤人。就在上个月，来自斯坦福团队，并发表于Nature的一篇最新研究《The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation》，更是将对AI的理解演示得出神入化，研究者们利用AI构建研究院多个Agents作为一个完整的虚拟实验室，并在Agents主导的思考和推导中，发现了新的SARS纳米抗体。面对聪慧强大甚过自己的Agent技术，研究员非但没有不自信，反而自信地用新的技术造福人类，拓宽自我，实现真正的豁达与成熟。

第二，在意义焦虑上，问题则更为隐性和深刻。我们常常思考，既然AI如此聪慧，它的能力，我这辈子都不可能企及，那么我的存在，还有什么意义？但这样的问题，从一开始就问错了，意义从来不取决于智识和能力多少的孤立加和。我们被抛入这个荒诞的世界，本无意义，本无目的。意义，需要我们以人独有的qualia和主体性，在推石上山的每一秒荒诞中，选择走出那嘲弄荒诞的下一步。意义，需要我们以人独有的定义权和感性权，在成为超人之后，由自己定义。维特根斯坦进一步告诉我们，世界绝不是物、客体的总和，而是事实的总和，而事实，就是主体与客体的交互过程，是我们在生活形式中，作为主体对于事物的使用。意义不在于学习知识和使用技术的结果，更不在于知识和技术本身，而在于我们学习和使用它们的过程。在这个过程中，我们将AI孤立的强大能力，经由自手，转化与应用于外部客体，才产生了新的事实与意义。在这个过程中，AI以其强大的能力映照出我们的选择、我们的提问、我们的创造，从而像一面镜子，帮助我们更清晰地看清自己的独特性和我们所创造的意义。因此，意义全不在于与大模型的攀比，而就在于当下的体验。而大模型却正好能够通过我们与其的交互——无论是令其工作还是向其学习——作为那个诠释与释放我们的意义的完美他者存在。那几位利用AI发现新抗体的研究者，他们的意义不在于比AI更会计算和预测分子结构，也不在于发明的新抗体本身，而在于：他们提出了“要寻找新抗体”这个伟大的目标，在于他们设计实验、解读数据的每一次探索、在于每一位后继者的一次新的citation与视域融合，乃至于，未来其生发出的一切，每一次拯救生命的全过程。这所有的、充满智慧与勇气、人性与理性光辉的事实们，才是意义本身。

然而最终我们要超越的，不仅仅是“过度自信”或“过度不自信”，也应是因AI产生的任何“自信”、“不自信”等等，错误的投射性认同本身。正如禅宗所言，“看山是山，看山不是山，看山还是山”。我们当然必须要从题目中，看山只是山的简单前反思脱离，但也绝不应止步于前文全文一般，建构与辩证的，看山不是山式的小心翼翼。面对这样一个先进的技术，我们要做的，仅仅是：抛下一切AI桎梏于”我“的执念，让它客观地，“如其所是”地存在。从而，我们才能达到那种，看山还是山的后批判平和。我们平静地，不带情感地使用，或不使用它，无论它是什么模样。我们在其中创造归于事实本身的意义，仅此而已。我们既不因AI的夸赞而沾沾自喜，也不因其强大而妄自菲薄，只是平静地问：这个工具，如何能帮助我更好地提出问题、更深刻地理解世界、更有力地创造价值？这个工具，如何能作为客体，在与“我”作为主体的交互中，产生更多有价值的事实和意义？

只有当我们超越了一切感性的认知滤镜，用真正理性的思维来”无我“一般地体验和使用AI——我们才能真正获得那种，妙用AI、善用AI的底层能力，并不让自己堕入任何认知负债或认知自卑的深渊。